{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "TRAIN_VAL_DATASET = \"final_datasets/train_val/final.csv\"\n",
    "TEST_DATASET = \"final_datasets/test/final.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "df_train_val = pd.read_csv(TRAIN_VAL_DATASET)\n",
    "df_test = pd.read_csv(TEST_DATASET)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_acceptance_rate, core_contributor_flag, previous_prs, year_created, time_to_close, comments_burstiness, num_comments, num_reviewers, avg_max_args, avg_multi_comments, max_max_cc, min_call_count, pr_time_label]\n",
      "Index: []\n",
      "Number of identical rows: 0\n"
     ]
    }
   ],
   "source": [
    "common = pd.merge(df_train_val, df_test, how='inner')\n",
    "print(common)\n",
    "print(\"Number of identical rows:\", len(common))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "      author_acceptance_rate  core_contributor_flag  previous_prs  \\\n0                        0.0                      0             0   \n1                        0.0                      0             1   \n2                        0.0                      0             0   \n3                        0.0                      0             0   \n4                        0.0                      0             0   \n...                      ...                    ...           ...   \n5995                     0.0                      0             0   \n5996                     0.0                      0             0   \n5997                     0.0                      0             1   \n5998                     0.0                      0             2   \n5999                     0.0                      0             3   \n\n      year_created  time_to_close  comments_burstiness  num_comments  \\\n0             2025       0.067222             0.000000             2   \n1             2025      42.694444             0.000000             1   \n2             2024    4293.194444             0.000000             1   \n3             2024       4.407222             0.586390             3   \n4             2020       0.921667             0.000000             0   \n...            ...            ...                  ...           ...   \n5995          2024     932.561667             0.000000             0   \n5996          2020       1.350833             0.998579             3   \n5997          2021      28.285000             2.063491             8   \n5998          2021       0.135833             0.000000             0   \n5999          2025       0.261944             1.000000             3   \n\n      num_reviewers  avg_max_args  avg_multi_comments  max_max_cc  \\\n0                 2      9.000000          135.000000        10.0   \n1                 1      9.000000          135.000000        10.0   \n2                 1      2.000000           58.000000         1.0   \n3                 3      3.500000           76.500000         6.0   \n4                 0     17.000000            0.000000        17.0   \n...             ...           ...                 ...         ...   \n5995              0      2.000000           12.500000        13.0   \n5996              1      5.000000           20.000000        21.0   \n5997              1      2.500000           22.500000         8.0   \n5998              0      4.307692           88.923077        27.0   \n5999              1      4.000000           32.500000        13.0   \n\n      min_call_count pr_time_label  \n0               88.0      rejected  \n1               88.0      rejected  \n2              236.0      accepted  \n3               63.0      accepted  \n4              251.0      rejected  \n...              ...           ...  \n5995             0.0      rejected  \n5996           206.0      rejected  \n5997            64.0      rejected  \n5998             1.0      rejected  \n5999           141.0      rejected  \n\n[6000 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_acceptance_rate</th>\n      <th>core_contributor_flag</th>\n      <th>previous_prs</th>\n      <th>year_created</th>\n      <th>time_to_close</th>\n      <th>comments_burstiness</th>\n      <th>num_comments</th>\n      <th>num_reviewers</th>\n      <th>avg_max_args</th>\n      <th>avg_multi_comments</th>\n      <th>max_max_cc</th>\n      <th>min_call_count</th>\n      <th>pr_time_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2025</td>\n      <td>0.067222</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9.000000</td>\n      <td>135.000000</td>\n      <td>10.0</td>\n      <td>88.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2025</td>\n      <td>42.694444</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.000000</td>\n      <td>135.000000</td>\n      <td>10.0</td>\n      <td>88.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2024</td>\n      <td>4293.194444</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>58.000000</td>\n      <td>1.0</td>\n      <td>236.0</td>\n      <td>accepted</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2024</td>\n      <td>4.407222</td>\n      <td>0.586390</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3.500000</td>\n      <td>76.500000</td>\n      <td>6.0</td>\n      <td>63.0</td>\n      <td>accepted</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2020</td>\n      <td>0.921667</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17.000000</td>\n      <td>0.000000</td>\n      <td>17.0</td>\n      <td>251.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2024</td>\n      <td>932.561667</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>12.500000</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2020</td>\n      <td>1.350833</td>\n      <td>0.998579</td>\n      <td>3</td>\n      <td>1</td>\n      <td>5.000000</td>\n      <td>20.000000</td>\n      <td>21.0</td>\n      <td>206.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2021</td>\n      <td>28.285000</td>\n      <td>2.063491</td>\n      <td>8</td>\n      <td>1</td>\n      <td>2.500000</td>\n      <td>22.500000</td>\n      <td>8.0</td>\n      <td>64.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2021</td>\n      <td>0.135833</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.307692</td>\n      <td>88.923077</td>\n      <td>27.0</td>\n      <td>1.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2025</td>\n      <td>0.261944</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4.000000</td>\n      <td>32.500000</td>\n      <td>13.0</td>\n      <td>141.0</td>\n      <td>rejected</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val.round()\n",
    "df_train_val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author_acceptance_rate', 'core_contributor_flag', 'previous_prs', 'year_created', 'time_to_close', 'comments_burstiness', 'num_comments', 'num_reviewers', 'avg_max_args', 'avg_multi_comments', 'max_max_cc', 'min_call_count', 'pr_time_label']\n"
     ]
    }
   ],
   "source": [
    "print(df_train_val.columns.tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "      author_acceptance_rate  core_contributor_flag  previous_prs  \\\n0                        0.0                      0             0   \n1                        0.0                      0             0   \n2                        0.0                      0             1   \n3                        0.0                      0             0   \n4                        0.0                      0             1   \n...                      ...                    ...           ...   \n6951                     0.0                      0             0   \n6952                     1.0                      0             1   \n6953                     0.0                      0             0   \n6954                     0.0                      0             0   \n6955                     0.0                      0             1   \n\n      year_created  time_to_close  comments_burstiness  num_comments  \\\n0             2025      14.806111             0.000000             1   \n1             2018    1173.121389             0.674944            10   \n2             2018       0.214722             0.000000             0   \n3             2025       0.958889             0.000000             0   \n4             2025    1308.575556             0.000000             2   \n...            ...            ...                  ...           ...   \n6951          2025       1.478611             0.000000             2   \n6952          2025      18.141667             0.000000             1   \n6953          2024     174.446389             0.000000             1   \n6954          2017    1241.131389             2.558994            12   \n6955          2017     665.305556             1.204682             4   \n\n      num_reviewers  avg_max_args  avg_multi_comments  max_max_cc  \\\n0                 1       11.0000         1467.000000        36.0   \n1                 5        4.0625           44.437500        30.0   \n2                 0        5.0000         1067.000000        15.0   \n3                 0        3.0000            6.500000        13.0   \n4                 2       11.0000          187.000000        56.0   \n...             ...           ...                 ...         ...   \n6951              2        5.0000          715.000000        25.0   \n6952              1        6.0000          380.666667        15.0   \n6953              1        5.0000           11.000000         8.0   \n6954              3       11.5000          369.000000        39.0   \n6955              3       20.0000          739.000000        39.0   \n\n      min_call_count pr_time_label  \n0              250.0      rejected  \n1               79.0      rejected  \n2              287.0      rejected  \n3               26.0      rejected  \n4              142.0      rejected  \n...              ...           ...  \n6951            95.0      accepted  \n6952           337.0      accepted  \n6953          4097.0      accepted  \n6954           243.0      rejected  \n6955           246.0      rejected  \n\n[6956 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author_acceptance_rate</th>\n      <th>core_contributor_flag</th>\n      <th>previous_prs</th>\n      <th>year_created</th>\n      <th>time_to_close</th>\n      <th>comments_burstiness</th>\n      <th>num_comments</th>\n      <th>num_reviewers</th>\n      <th>avg_max_args</th>\n      <th>avg_multi_comments</th>\n      <th>max_max_cc</th>\n      <th>min_call_count</th>\n      <th>pr_time_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2025</td>\n      <td>14.806111</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11.0000</td>\n      <td>1467.000000</td>\n      <td>36.0</td>\n      <td>250.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2018</td>\n      <td>1173.121389</td>\n      <td>0.674944</td>\n      <td>10</td>\n      <td>5</td>\n      <td>4.0625</td>\n      <td>44.437500</td>\n      <td>30.0</td>\n      <td>79.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2018</td>\n      <td>0.214722</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0000</td>\n      <td>1067.000000</td>\n      <td>15.0</td>\n      <td>287.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2025</td>\n      <td>0.958889</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0000</td>\n      <td>6.500000</td>\n      <td>13.0</td>\n      <td>26.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2025</td>\n      <td>1308.575556</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11.0000</td>\n      <td>187.000000</td>\n      <td>56.0</td>\n      <td>142.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6951</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2025</td>\n      <td>1.478611</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5.0000</td>\n      <td>715.000000</td>\n      <td>25.0</td>\n      <td>95.0</td>\n      <td>accepted</td>\n    </tr>\n    <tr>\n      <th>6952</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2025</td>\n      <td>18.141667</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.0000</td>\n      <td>380.666667</td>\n      <td>15.0</td>\n      <td>337.0</td>\n      <td>accepted</td>\n    </tr>\n    <tr>\n      <th>6953</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2024</td>\n      <td>174.446389</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.0000</td>\n      <td>11.000000</td>\n      <td>8.0</td>\n      <td>4097.0</td>\n      <td>accepted</td>\n    </tr>\n    <tr>\n      <th>6954</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>1241.131389</td>\n      <td>2.558994</td>\n      <td>12</td>\n      <td>3</td>\n      <td>11.5000</td>\n      <td>369.000000</td>\n      <td>39.0</td>\n      <td>243.0</td>\n      <td>rejected</td>\n    </tr>\n    <tr>\n      <th>6955</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2017</td>\n      <td>665.305556</td>\n      <td>1.204682</td>\n      <td>4</td>\n      <td>3</td>\n      <td>20.0000</td>\n      <td>739.000000</td>\n      <td>39.0</td>\n      <td>246.0</td>\n      <td>rejected</td>\n    </tr>\n  </tbody>\n</table>\n<p>6956 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[df_train_val.columns]\n",
    "df_test.round()\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_acceptance_rate, core_contributor_flag, previous_prs, year_created, time_to_close, comments_burstiness, num_comments, num_reviewers, avg_max_args, avg_multi_comments, max_max_cc, min_call_count, pr_time_label]\n",
      "Index: []\n",
      "Number of identical rows: 0\n"
     ]
    }
   ],
   "source": [
    "common = pd.merge(df_train_val, df_test, how='inner')\n",
    "print(common)\n",
    "print(\"Number of identical rows:\", len(common))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL MAP = {'rejected': 0, 'accepted': 1}\n"
     ]
    }
   ],
   "source": [
    "label_values = sorted(df_train_val['pr_time_label'].unique(), reverse = True)\n",
    "label_map = {label: i for i, label in enumerate(label_values)}\n",
    "print(\"LABEL MAP =\", label_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = df_train_val.drop(\"pr_time_label\", axis=1)\n",
    "y = df_train_val['pr_time_label'].map(label_map).values\n",
    "print(\"Encoded labels:\", np.unique(y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4800, Validation size: 1200\n",
      "Distribution train:  (array([0, 1]), array([2009, 2791]))\n",
      "Distribution val:  (array([0, 1]), array([502, 698]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}\")\n",
    "print(\"Distribution train: \", np.unique(y_train, return_counts=True))\n",
    "print(\"Distribution val: \", np.unique(y_val, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(1.1946241911398705), 1: np.float64(0.8599068434252956)}\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1]\n",
      "Distribution test:  (array([0, 1]), array([3910, 3046]))\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(\"pr_time_label\", axis=1)\n",
    "y_test = df_test['pr_time_label'].map(label_map).values\n",
    "print(\"Encoded labels:\", np.unique(y_test))\n",
    "print(\"Distribution test: \", np.unique(y_test, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8260416666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7817    0.8109    0.7960      2009\n",
      "           1     0.8601    0.8370    0.8484      2791\n",
      "\n",
      "    accuracy                         0.8260      4800\n",
      "   macro avg     0.8209    0.8239    0.8222      4800\n",
      "weighted avg     0.8273    0.8260    0.8265      4800\n",
      "\n",
      "Validation Accuracy: 0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7636    0.7849    0.7741       502\n",
      "           1     0.8421    0.8252    0.8336       698\n",
      "\n",
      "    accuracy                         0.8083      1200\n",
      "   macro avg     0.8028    0.8050    0.8038      1200\n",
      "weighted avg     0.8092    0.8083    0.8087      1200\n",
      "\n",
      "Testing Accuracy: 0.8225991949396205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8202    0.8765    0.8474      3910\n",
      "           1     0.8261    0.7534    0.7881      3046\n",
      "\n",
      "    accuracy                         0.8226      6956\n",
      "   macro avg     0.8232    0.8150    0.8178      6956\n",
      "weighted avg     0.8228    0.8226    0.8215      6956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=15,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=50,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred_train = rf.predict(X_train)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, rf_pred_train))\n",
    "print(classification_report(y_train, rf_pred_train, digits=4))\n",
    "\n",
    "rf_pred_val = rf.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, rf_pred_val))\n",
    "print(classification_report(y_val, rf_pred_val, digits=4))\n",
    "\n",
    "rf_pred_test = rf.predict(X_test)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, rf_pred_test))\n",
    "print(classification_report(y_test, rf_pred_test, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64281\n",
      "[50]\tvalidation_0-logloss:0.42712\n",
      "[100]\tvalidation_0-logloss:0.41077\n",
      "[150]\tvalidation_0-logloss:0.40601\n",
      "[200]\tvalidation_0-logloss:0.40404\n",
      "[250]\tvalidation_0-logloss:0.40151\n",
      "[300]\tvalidation_0-logloss:0.40081\n",
      "[329]\tvalidation_0-logloss:0.40156\n",
      "Training Accuracy: 0.8541666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8386    0.8069    0.8224      2009\n",
      "           1     0.8647    0.8882    0.8763      2791\n",
      "\n",
      "    accuracy                         0.8542      4800\n",
      "   macro avg     0.8516    0.8475    0.8494      4800\n",
      "weighted avg     0.8538    0.8542    0.8537      4800\n",
      "\n",
      "Validation Accuracy: 0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.7490    0.7737       502\n",
      "           1     0.8274    0.8653    0.8459       698\n",
      "\n",
      "    accuracy                         0.8167      1200\n",
      "   macro avg     0.8137    0.8072    0.8098      1200\n",
      "weighted avg     0.8159    0.8167    0.8157      1200\n",
      "\n",
      "Testing Accuracy: 0.8039102932719954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8187    0.8363    0.8274      3910\n",
      "           1     0.7839    0.7623    0.7730      3046\n",
      "\n",
      "    accuracy                         0.8039      6956\n",
      "   macro avg     0.8013    0.7993    0.8002      6956\n",
      "weighted avg     0.8035    0.8039    0.8036      6956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=330,       # OK fewer trees for stability\n",
    "    max_depth=2,            # OK slightly deeper than before\n",
    "    learning_rate=0.118,    # OK slightly higher to learn faster\n",
    "    subsample=0.8,          # OK row sampling\n",
    "    colsample_bytree=0.9,   # OK feature sampling\n",
    "    gamma=0.1,              # OK minimum loss reduction\n",
    "    reg_alpha=0.05,         # OK mild L1 regularization\n",
    "    reg_lambda=1.0,         # OK L2 regularization\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "xgb_pred_train = xgb.predict(X_train)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, xgb_pred_train))\n",
    "print(classification_report(y_train, xgb_pred_train, digits=4))\n",
    "\n",
    "xgb_pred_val = xgb.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, xgb_pred_val))\n",
    "print(classification_report(y_val, xgb_pred_val, digits=4))\n",
    "\n",
    "xgb_pred_test = xgb.predict(X_test)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, xgb_pred_test))\n",
    "print(classification_report(y_test, xgb_pred_test, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7952    0.8847    0.8375      3910\n",
      "           1     0.8269    0.7075    0.7626      3046\n",
      "\n",
      "    accuracy                         0.8071      6956\n",
      "   macro avg     0.8111    0.7961    0.8000      6956\n",
      "weighted avg     0.8091    0.8071    0.8047      6956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_proba = xgb.predict_proba(X_test)[:,1]\n",
    "threshold = 0.58\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7714583\ttest: 0.7791667\tbest: 0.7791667 (0)\ttotal: 1.3ms\tremaining: 13s\n",
      "50:\tlearn: 0.7704167\ttest: 0.7800000\tbest: 0.7808333 (25)\ttotal: 83.2ms\tremaining: 16.2s\n",
      "100:\tlearn: 0.7706250\ttest: 0.7800000\tbest: 0.7808333 (25)\ttotal: 161ms\tremaining: 15.8s\n",
      "150:\tlearn: 0.7725000\ttest: 0.7800000\tbest: 0.7808333 (25)\ttotal: 237ms\tremaining: 15.5s\n",
      "200:\tlearn: 0.7737500\ttest: 0.7808333\tbest: 0.7808333 (25)\ttotal: 311ms\tremaining: 15.2s\n",
      "250:\tlearn: 0.7739583\ttest: 0.7808333\tbest: 0.7808333 (25)\ttotal: 385ms\tremaining: 14.9s\n",
      "300:\tlearn: 0.7752083\ttest: 0.7800000\tbest: 0.7808333 (25)\ttotal: 463ms\tremaining: 14.9s\n",
      "350:\tlearn: 0.7756250\ttest: 0.7808333\tbest: 0.7808333 (25)\ttotal: 540ms\tremaining: 14.8s\n",
      "400:\tlearn: 0.7758333\ttest: 0.7816667\tbest: 0.7816667 (352)\ttotal: 622ms\tremaining: 14.9s\n",
      "450:\tlearn: 0.7775000\ttest: 0.7808333\tbest: 0.7816667 (352)\ttotal: 705ms\tremaining: 14.9s\n",
      "500:\tlearn: 0.7775000\ttest: 0.7816667\tbest: 0.7816667 (352)\ttotal: 782ms\tremaining: 14.8s\n",
      "550:\tlearn: 0.7781250\ttest: 0.7816667\tbest: 0.7816667 (352)\ttotal: 862ms\tremaining: 14.8s\n",
      "600:\tlearn: 0.7808333\ttest: 0.7800000\tbest: 0.7816667 (352)\ttotal: 945ms\tremaining: 14.8s\n",
      "650:\tlearn: 0.7820833\ttest: 0.7783333\tbest: 0.7816667 (352)\ttotal: 1.03s\tremaining: 14.8s\n",
      "700:\tlearn: 0.7827083\ttest: 0.7758333\tbest: 0.7816667 (352)\ttotal: 1.11s\tremaining: 14.7s\n",
      "750:\tlearn: 0.7829167\ttest: 0.7758333\tbest: 0.7816667 (352)\ttotal: 1.19s\tremaining: 14.6s\n",
      "800:\tlearn: 0.7835417\ttest: 0.7758333\tbest: 0.7816667 (352)\ttotal: 1.26s\tremaining: 14.5s\n",
      "850:\tlearn: 0.7837500\ttest: 0.7766667\tbest: 0.7816667 (352)\ttotal: 1.34s\tremaining: 14.4s\n",
      "900:\tlearn: 0.7891667\ttest: 0.7816667\tbest: 0.7825000 (887)\ttotal: 1.42s\tremaining: 14.3s\n",
      "950:\tlearn: 0.7891667\ttest: 0.7833333\tbest: 0.7841667 (927)\ttotal: 1.49s\tremaining: 14.2s\n",
      "1000:\tlearn: 0.7893750\ttest: 0.7850000\tbest: 0.7850000 (988)\ttotal: 1.56s\tremaining: 14.1s\n",
      "1050:\tlearn: 0.7916667\ttest: 0.7875000\tbest: 0.7875000 (1047)\ttotal: 1.64s\tremaining: 14s\n",
      "1100:\tlearn: 0.7960417\ttest: 0.7916667\tbest: 0.7925000 (1097)\ttotal: 1.72s\tremaining: 13.9s\n",
      "1150:\tlearn: 0.7985417\ttest: 0.7908333\tbest: 0.7925000 (1097)\ttotal: 1.79s\tremaining: 13.8s\n",
      "1200:\tlearn: 0.7995833\ttest: 0.7925000\tbest: 0.7925000 (1097)\ttotal: 1.86s\tremaining: 13.7s\n",
      "1250:\tlearn: 0.8002083\ttest: 0.7925000\tbest: 0.7925000 (1097)\ttotal: 1.94s\tremaining: 13.6s\n",
      "1300:\tlearn: 0.8008333\ttest: 0.7933333\tbest: 0.7933333 (1254)\ttotal: 2.01s\tremaining: 13.5s\n",
      "1350:\tlearn: 0.8006250\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 2.09s\tremaining: 13.4s\n",
      "1400:\tlearn: 0.8008333\ttest: 0.7908333\tbest: 0.7933333 (1254)\ttotal: 2.16s\tremaining: 13.3s\n",
      "1450:\tlearn: 0.8014583\ttest: 0.7916667\tbest: 0.7933333 (1254)\ttotal: 2.24s\tremaining: 13.2s\n",
      "1500:\tlearn: 0.8014583\ttest: 0.7916667\tbest: 0.7933333 (1254)\ttotal: 2.31s\tremaining: 13.1s\n",
      "1550:\tlearn: 0.8016667\ttest: 0.7916667\tbest: 0.7933333 (1254)\ttotal: 2.39s\tremaining: 13s\n",
      "1600:\tlearn: 0.8012500\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 2.46s\tremaining: 12.9s\n",
      "1650:\tlearn: 0.8027083\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 2.54s\tremaining: 12.9s\n",
      "1700:\tlearn: 0.8027083\ttest: 0.7900000\tbest: 0.7933333 (1254)\ttotal: 2.62s\tremaining: 12.8s\n",
      "1750:\tlearn: 0.8029167\ttest: 0.7900000\tbest: 0.7933333 (1254)\ttotal: 2.7s\tremaining: 12.7s\n",
      "1800:\tlearn: 0.8039583\ttest: 0.7900000\tbest: 0.7933333 (1254)\ttotal: 2.77s\tremaining: 12.6s\n",
      "1850:\tlearn: 0.8052083\ttest: 0.7908333\tbest: 0.7933333 (1254)\ttotal: 2.84s\tremaining: 12.5s\n",
      "1900:\tlearn: 0.8056250\ttest: 0.7916667\tbest: 0.7933333 (1254)\ttotal: 2.92s\tremaining: 12.5s\n",
      "1950:\tlearn: 0.8052083\ttest: 0.7908333\tbest: 0.7933333 (1254)\ttotal: 3s\tremaining: 12.4s\n",
      "2000:\tlearn: 0.8050000\ttest: 0.7908333\tbest: 0.7933333 (1254)\ttotal: 3.08s\tremaining: 12.3s\n",
      "2050:\tlearn: 0.8052083\ttest: 0.7916667\tbest: 0.7933333 (1254)\ttotal: 3.16s\tremaining: 12.2s\n",
      "2100:\tlearn: 0.8064583\ttest: 0.7908333\tbest: 0.7933333 (1254)\ttotal: 3.23s\tremaining: 12.2s\n",
      "2150:\tlearn: 0.8068750\ttest: 0.7900000\tbest: 0.7933333 (1254)\ttotal: 3.31s\tremaining: 12.1s\n",
      "2200:\tlearn: 0.8068750\ttest: 0.7900000\tbest: 0.7933333 (1254)\ttotal: 3.39s\tremaining: 12s\n",
      "2250:\tlearn: 0.8070833\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 3.46s\tremaining: 11.9s\n",
      "2300:\tlearn: 0.8081250\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 3.53s\tremaining: 11.8s\n",
      "2350:\tlearn: 0.8085417\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 3.6s\tremaining: 11.7s\n",
      "2400:\tlearn: 0.8085417\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 3.67s\tremaining: 11.6s\n",
      "2450:\tlearn: 0.8097917\ttest: 0.7925000\tbest: 0.7933333 (1254)\ttotal: 3.74s\tremaining: 11.5s\n",
      "2500:\tlearn: 0.8102083\ttest: 0.7941667\tbest: 0.7941667 (2494)\ttotal: 3.81s\tremaining: 11.4s\n",
      "2550:\tlearn: 0.8100000\ttest: 0.7933333\tbest: 0.7941667 (2494)\ttotal: 3.89s\tremaining: 11.3s\n",
      "2600:\tlearn: 0.8104167\ttest: 0.7950000\tbest: 0.7950000 (2580)\ttotal: 3.96s\tremaining: 11.3s\n",
      "2650:\tlearn: 0.8108333\ttest: 0.7958333\tbest: 0.7966667 (2623)\ttotal: 4.03s\tremaining: 11.2s\n",
      "2700:\tlearn: 0.8110417\ttest: 0.7975000\tbest: 0.7975000 (2690)\ttotal: 4.1s\tremaining: 11.1s\n",
      "2750:\tlearn: 0.8114583\ttest: 0.7991667\tbest: 0.8000000 (2736)\ttotal: 4.17s\tremaining: 11s\n",
      "2800:\tlearn: 0.8114583\ttest: 0.7991667\tbest: 0.8000000 (2736)\ttotal: 4.24s\tremaining: 10.9s\n",
      "2850:\tlearn: 0.8116667\ttest: 0.8000000\tbest: 0.8000000 (2736)\ttotal: 4.32s\tremaining: 10.8s\n",
      "2900:\tlearn: 0.8129167\ttest: 0.8008333\tbest: 0.8008333 (2873)\ttotal: 4.4s\tremaining: 10.8s\n",
      "2950:\tlearn: 0.8139583\ttest: 0.8016667\tbest: 0.8016667 (2916)\ttotal: 4.47s\tremaining: 10.7s\n",
      "3000:\tlearn: 0.8143750\ttest: 0.8016667\tbest: 0.8016667 (2916)\ttotal: 4.55s\tremaining: 10.6s\n",
      "3050:\tlearn: 0.8141667\ttest: 0.8016667\tbest: 0.8016667 (2916)\ttotal: 4.63s\tremaining: 10.5s\n",
      "3100:\tlearn: 0.8135417\ttest: 0.8016667\tbest: 0.8016667 (2916)\ttotal: 4.73s\tremaining: 10.5s\n",
      "3150:\tlearn: 0.8139583\ttest: 0.8016667\tbest: 0.8016667 (2916)\ttotal: 4.83s\tremaining: 10.5s\n",
      "3200:\tlearn: 0.8135417\ttest: 0.7991667\tbest: 0.8016667 (2916)\ttotal: 4.89s\tremaining: 10.4s\n",
      "3250:\tlearn: 0.8137500\ttest: 0.8008333\tbest: 0.8016667 (2916)\ttotal: 4.97s\tremaining: 10.3s\n",
      "3300:\tlearn: 0.8135417\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 5.04s\tremaining: 10.2s\n",
      "3350:\tlearn: 0.8135417\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 5.11s\tremaining: 10.1s\n",
      "3400:\tlearn: 0.8139583\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 5.18s\tremaining: 10.1s\n",
      "3450:\tlearn: 0.8139583\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.26s\tremaining: 9.97s\n",
      "3500:\tlearn: 0.8141667\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.33s\tremaining: 9.9s\n",
      "3550:\tlearn: 0.8139583\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.4s\tremaining: 9.81s\n",
      "3600:\tlearn: 0.8145833\ttest: 0.8000000\tbest: 0.8025000 (3297)\ttotal: 5.47s\tremaining: 9.73s\n",
      "3650:\tlearn: 0.8145833\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 5.55s\tremaining: 9.64s\n",
      "3700:\tlearn: 0.8145833\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.62s\tremaining: 9.56s\n",
      "3750:\tlearn: 0.8139583\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.69s\tremaining: 9.48s\n",
      "3800:\tlearn: 0.8147917\ttest: 0.8008333\tbest: 0.8025000 (3297)\ttotal: 5.76s\tremaining: 9.4s\n",
      "3850:\tlearn: 0.8152083\ttest: 0.8000000\tbest: 0.8025000 (3297)\ttotal: 5.84s\tremaining: 9.33s\n",
      "3900:\tlearn: 0.8150000\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 5.91s\tremaining: 9.24s\n",
      "3950:\tlearn: 0.8156250\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 5.98s\tremaining: 9.16s\n",
      "4000:\tlearn: 0.8150000\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 6.05s\tremaining: 9.08s\n",
      "4050:\tlearn: 0.8154167\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.13s\tremaining: 9s\n",
      "4100:\tlearn: 0.8152083\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 6.2s\tremaining: 8.92s\n",
      "4150:\tlearn: 0.8154167\ttest: 0.8016667\tbest: 0.8025000 (3297)\ttotal: 6.28s\tremaining: 8.85s\n",
      "4200:\tlearn: 0.8154167\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.36s\tremaining: 8.79s\n",
      "4250:\tlearn: 0.8156250\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.44s\tremaining: 8.71s\n",
      "4300:\tlearn: 0.8158333\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.51s\tremaining: 8.63s\n",
      "4350:\tlearn: 0.8154167\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.58s\tremaining: 8.55s\n",
      "4400:\tlearn: 0.8154167\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.66s\tremaining: 8.47s\n",
      "4450:\tlearn: 0.8156250\ttest: 0.8025000\tbest: 0.8025000 (3297)\ttotal: 6.74s\tremaining: 8.4s\n",
      "4500:\tlearn: 0.8154167\ttest: 0.8033333\tbest: 0.8033333 (4456)\ttotal: 6.85s\tremaining: 8.37s\n",
      "4550:\tlearn: 0.8158333\ttest: 0.8033333\tbest: 0.8041667 (4526)\ttotal: 6.92s\tremaining: 8.28s\n",
      "4600:\tlearn: 0.8164583\ttest: 0.8033333\tbest: 0.8041667 (4526)\ttotal: 7s\tremaining: 8.21s\n",
      "4650:\tlearn: 0.8164583\ttest: 0.8041667\tbest: 0.8041667 (4526)\ttotal: 7.07s\tremaining: 8.13s\n",
      "4700:\tlearn: 0.8166667\ttest: 0.8033333\tbest: 0.8041667 (4526)\ttotal: 7.15s\tremaining: 8.05s\n",
      "4750:\tlearn: 0.8164583\ttest: 0.8041667\tbest: 0.8041667 (4526)\ttotal: 7.23s\tremaining: 7.99s\n",
      "4800:\tlearn: 0.8164583\ttest: 0.8041667\tbest: 0.8041667 (4526)\ttotal: 7.33s\tremaining: 7.94s\n",
      "4850:\tlearn: 0.8162500\ttest: 0.8041667\tbest: 0.8041667 (4526)\ttotal: 7.4s\tremaining: 7.86s\n",
      "4900:\tlearn: 0.8164583\ttest: 0.8050000\tbest: 0.8050000 (4892)\ttotal: 7.47s\tremaining: 7.78s\n",
      "4950:\tlearn: 0.8164583\ttest: 0.8050000\tbest: 0.8058333 (4921)\ttotal: 7.55s\tremaining: 7.7s\n",
      "5000:\tlearn: 0.8168750\ttest: 0.8058333\tbest: 0.8058333 (4921)\ttotal: 7.63s\tremaining: 7.62s\n",
      "5050:\tlearn: 0.8168750\ttest: 0.8058333\tbest: 0.8058333 (4921)\ttotal: 7.7s\tremaining: 7.54s\n",
      "5100:\tlearn: 0.8172917\ttest: 0.8066667\tbest: 0.8066667 (5080)\ttotal: 7.78s\tremaining: 7.47s\n",
      "5150:\tlearn: 0.8177083\ttest: 0.8075000\tbest: 0.8075000 (5111)\ttotal: 7.86s\tremaining: 7.4s\n",
      "5200:\tlearn: 0.8179167\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 7.93s\tremaining: 7.32s\n",
      "5250:\tlearn: 0.8183333\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 8.01s\tremaining: 7.24s\n",
      "5300:\tlearn: 0.8181250\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 8.08s\tremaining: 7.16s\n",
      "5350:\tlearn: 0.8181250\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 8.16s\tremaining: 7.09s\n",
      "5400:\tlearn: 0.8183333\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 8.23s\tremaining: 7s\n",
      "5450:\tlearn: 0.8185417\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 8.3s\tremaining: 6.92s\n",
      "5500:\tlearn: 0.8185417\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.37s\tremaining: 6.85s\n",
      "5550:\tlearn: 0.8187500\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.45s\tremaining: 6.77s\n",
      "5600:\tlearn: 0.8187500\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.52s\tremaining: 6.69s\n",
      "5650:\tlearn: 0.8185417\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.59s\tremaining: 6.61s\n",
      "5700:\tlearn: 0.8187500\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.66s\tremaining: 6.53s\n",
      "5750:\tlearn: 0.8183333\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.74s\tremaining: 6.46s\n",
      "5800:\tlearn: 0.8183333\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.82s\tremaining: 6.38s\n",
      "5850:\tlearn: 0.8179167\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.89s\tremaining: 6.31s\n",
      "5900:\tlearn: 0.8177083\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 8.96s\tremaining: 6.22s\n",
      "5950:\tlearn: 0.8185417\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.04s\tremaining: 6.15s\n",
      "6000:\tlearn: 0.8181250\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.12s\tremaining: 6.08s\n",
      "6050:\tlearn: 0.8185417\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.19s\tremaining: 6s\n",
      "6100:\tlearn: 0.8181250\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.27s\tremaining: 5.92s\n",
      "6150:\tlearn: 0.8181250\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.34s\tremaining: 5.84s\n",
      "6200:\tlearn: 0.8181250\ttest: 0.8075000\tbest: 0.8083333 (5190)\ttotal: 9.41s\tremaining: 5.76s\n",
      "6250:\tlearn: 0.8183333\ttest: 0.8083333\tbest: 0.8083333 (5190)\ttotal: 9.49s\tremaining: 5.69s\n",
      "6300:\tlearn: 0.8185417\ttest: 0.8091667\tbest: 0.8091667 (6263)\ttotal: 9.57s\tremaining: 5.62s\n",
      "6350:\tlearn: 0.8191667\ttest: 0.8083333\tbest: 0.8091667 (6263)\ttotal: 9.64s\tremaining: 5.54s\n",
      "6400:\tlearn: 0.8189583\ttest: 0.8091667\tbest: 0.8091667 (6263)\ttotal: 9.72s\tremaining: 5.46s\n",
      "6450:\tlearn: 0.8187500\ttest: 0.8091667\tbest: 0.8091667 (6263)\ttotal: 9.8s\tremaining: 5.39s\n",
      "6500:\tlearn: 0.8191667\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 9.88s\tremaining: 5.32s\n",
      "6550:\tlearn: 0.8193750\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 9.96s\tremaining: 5.24s\n",
      "6600:\tlearn: 0.8193750\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10s\tremaining: 5.17s\n",
      "6650:\tlearn: 0.8195833\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.1s\tremaining: 5.09s\n",
      "6700:\tlearn: 0.8197917\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.2s\tremaining: 5.01s\n",
      "6750:\tlearn: 0.8200000\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.3s\tremaining: 4.93s\n",
      "6800:\tlearn: 0.8200000\ttest: 0.8091667\tbest: 0.8100000 (6465)\ttotal: 10.3s\tremaining: 4.86s\n",
      "6850:\tlearn: 0.8197917\ttest: 0.8091667\tbest: 0.8100000 (6465)\ttotal: 10.4s\tremaining: 4.79s\n",
      "6900:\tlearn: 0.8200000\ttest: 0.8091667\tbest: 0.8100000 (6465)\ttotal: 10.5s\tremaining: 4.71s\n",
      "6950:\tlearn: 0.8197917\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.6s\tremaining: 4.64s\n",
      "7000:\tlearn: 0.8202083\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.7s\tremaining: 4.56s\n",
      "7050:\tlearn: 0.8200000\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.7s\tremaining: 4.49s\n",
      "7100:\tlearn: 0.8200000\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.8s\tremaining: 4.42s\n",
      "7150:\tlearn: 0.8197917\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 10.9s\tremaining: 4.34s\n",
      "7200:\tlearn: 0.8197917\ttest: 0.8100000\tbest: 0.8100000 (6465)\ttotal: 11s\tremaining: 4.26s\n",
      "7250:\tlearn: 0.8195833\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11s\tremaining: 4.19s\n",
      "7300:\tlearn: 0.8197917\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.1s\tremaining: 4.11s\n",
      "7350:\tlearn: 0.8200000\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.2s\tremaining: 4.04s\n",
      "7400:\tlearn: 0.8202083\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 11.3s\tremaining: 3.96s\n",
      "7450:\tlearn: 0.8202083\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.4s\tremaining: 3.88s\n",
      "7500:\tlearn: 0.8202083\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.4s\tremaining: 3.81s\n",
      "7550:\tlearn: 0.8204167\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.5s\tremaining: 3.73s\n",
      "7600:\tlearn: 0.8208333\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 11.6s\tremaining: 3.66s\n",
      "7650:\tlearn: 0.8208333\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.7s\tremaining: 3.58s\n",
      "7700:\tlearn: 0.8210417\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 11.8s\tremaining: 3.51s\n",
      "7750:\tlearn: 0.8212500\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 11.8s\tremaining: 3.43s\n",
      "7800:\tlearn: 0.8214583\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 11.9s\tremaining: 3.35s\n",
      "7850:\tlearn: 0.8216667\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12s\tremaining: 3.28s\n",
      "7900:\tlearn: 0.8216667\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.1s\tremaining: 3.2s\n",
      "7950:\tlearn: 0.8218750\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.1s\tremaining: 3.13s\n",
      "8000:\tlearn: 0.8214583\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.2s\tremaining: 3.05s\n",
      "8050:\tlearn: 0.8214583\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.3s\tremaining: 2.98s\n",
      "8100:\tlearn: 0.8214583\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.4s\tremaining: 2.9s\n",
      "8150:\tlearn: 0.8212500\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.4s\tremaining: 2.82s\n",
      "8200:\tlearn: 0.8214583\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.5s\tremaining: 2.75s\n",
      "8250:\tlearn: 0.8216667\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 12.6s\tremaining: 2.67s\n",
      "8300:\tlearn: 0.8214583\ttest: 0.8100000\tbest: 0.8108333 (7204)\ttotal: 12.7s\tremaining: 2.6s\n",
      "8350:\tlearn: 0.8216667\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.8s\tremaining: 2.52s\n",
      "8400:\tlearn: 0.8216667\ttest: 0.8108333\tbest: 0.8108333 (7204)\ttotal: 12.9s\tremaining: 2.45s\n",
      "8450:\tlearn: 0.8218750\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 12.9s\tremaining: 2.37s\n",
      "8500:\tlearn: 0.8220833\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13s\tremaining: 2.29s\n",
      "8550:\tlearn: 0.8218750\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13.1s\tremaining: 2.22s\n",
      "8600:\tlearn: 0.8218750\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13.2s\tremaining: 2.14s\n",
      "8650:\tlearn: 0.8220833\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13.3s\tremaining: 2.07s\n",
      "8700:\tlearn: 0.8220833\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13.3s\tremaining: 1.99s\n",
      "8750:\tlearn: 0.8218750\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 13.4s\tremaining: 1.91s\n",
      "8800:\tlearn: 0.8222917\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.5s\tremaining: 1.84s\n",
      "8850:\tlearn: 0.8222917\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.6s\tremaining: 1.76s\n",
      "8900:\tlearn: 0.8222917\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.6s\tremaining: 1.68s\n",
      "8950:\tlearn: 0.8222917\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.7s\tremaining: 1.61s\n",
      "9000:\tlearn: 0.8225000\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.8s\tremaining: 1.53s\n",
      "9050:\tlearn: 0.8225000\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.9s\tremaining: 1.45s\n",
      "9100:\tlearn: 0.8225000\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 13.9s\tremaining: 1.38s\n",
      "9150:\tlearn: 0.8229167\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14s\tremaining: 1.3s\n",
      "9200:\tlearn: 0.8225000\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.1s\tremaining: 1.23s\n",
      "9250:\tlearn: 0.8227083\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.2s\tremaining: 1.15s\n",
      "9300:\tlearn: 0.8231250\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.3s\tremaining: 1.07s\n",
      "9350:\tlearn: 0.8229167\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.3s\tremaining: 995ms\n",
      "9400:\tlearn: 0.8227083\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.4s\tremaining: 919ms\n",
      "9450:\tlearn: 0.8229167\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.5s\tremaining: 842ms\n",
      "9500:\tlearn: 0.8227083\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.6s\tremaining: 766ms\n",
      "9550:\tlearn: 0.8227083\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.7s\tremaining: 689ms\n",
      "9600:\tlearn: 0.8227083\ttest: 0.8108333\tbest: 0.8116667 (8448)\ttotal: 14.7s\tremaining: 612ms\n",
      "9650:\tlearn: 0.8225000\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 14.8s\tremaining: 535ms\n",
      "9700:\tlearn: 0.8227083\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 14.9s\tremaining: 459ms\n",
      "9750:\tlearn: 0.8231250\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15s\tremaining: 382ms\n",
      "9800:\tlearn: 0.8229167\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15s\tremaining: 305ms\n",
      "9850:\tlearn: 0.8231250\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15.1s\tremaining: 229ms\n",
      "9900:\tlearn: 0.8231250\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15.2s\tremaining: 152ms\n",
      "9950:\tlearn: 0.8231250\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15.3s\tremaining: 75.2ms\n",
      "9999:\tlearn: 0.8231250\ttest: 0.8116667\tbest: 0.8116667 (8448)\ttotal: 15.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8116666667\n",
      "bestIteration = 8448\n",
      "\n",
      "Shrink model to first 8449 iterations.\n",
      "Training Accuracy: 0.821875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7815    0.7974    0.7894      2009\n",
      "           1     0.8520    0.8395    0.8457      2791\n",
      "\n",
      "    accuracy                         0.8219      4800\n",
      "   macro avg     0.8167    0.8184    0.8175      4800\n",
      "weighted avg     0.8225    0.8219    0.8221      4800\n",
      "\n",
      "Validation Accuracy: 0.8116666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7794    0.7669    0.7731       502\n",
      "           1     0.8343    0.8438    0.8390       698\n",
      "\n",
      "    accuracy                         0.8117      1200\n",
      "   macro avg     0.8068    0.8054    0.8061      1200\n",
      "weighted avg     0.8113    0.8117    0.8114      1200\n",
      "\n",
      "Testing Accuracy: 0.8018976423231743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8179    0.8330    0.8254      3910\n",
      "           1     0.7804    0.7620    0.7711      3046\n",
      "\n",
      "    accuracy                         0.8019      6956\n",
      "   macro avg     0.7992    0.7975    0.7982      6956\n",
      "weighted avg     0.8015    0.8019    0.8016      6956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(\n",
    "    iterations=10000,\n",
    "    learning_rate=0.01,\n",
    "    depth=1,\n",
    "    eval_metric='Accuracy',\n",
    "    random_seed=42,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "cat.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "cat_pred_train = cat.predict(X_train)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, cat_pred_train))\n",
    "print(classification_report(y_train, cat_pred_train, digits=4))\n",
    "\n",
    "cat_pred_val = cat.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, cat_pred_val))\n",
    "print(classification_report(y_val, cat_pred_val, digits=4))\n",
    "\n",
    "cat_pred_test = cat.predict(X_test)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, cat_pred_test))\n",
    "print(classification_report(y_test, cat_pred_test, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Desktop\\CISE - PR Acceptance Prediction\\venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.33162 | train_accuracy: 0.57042 | train_auc: 0.52204 | test_accuracy: 0.58833 | test_auc: 0.54071 |  0:00:21s\n",
      "epoch 1  | loss: 2.7854  | train_accuracy: 0.51021 | train_auc: 0.46045 | test_accuracy: 0.505   | test_auc: 0.45237 |  0:00:51s\n",
      "epoch 2  | loss: 2.10385 | train_accuracy: 0.57542 | train_auc: 0.49964 | test_accuracy: 0.575   | test_auc: 0.49809 |  0:01:17s\n",
      "epoch 3  | loss: 1.39215 | train_accuracy: 0.43854 | train_auc: 0.45936 | test_accuracy: 0.47333 | test_auc: 0.48599 |  0:01:44s\n",
      "epoch 4  | loss: 1.62114 | train_accuracy: 0.57729 | train_auc: 0.49405 | test_accuracy: 0.57667 | test_auc: 0.49269 |  0:02:08s\n",
      "epoch 5  | loss: 1.19028 | train_accuracy: 0.58208 | train_auc: 0.48855 | test_accuracy: 0.58083 | test_auc: 0.49047 |  0:02:34s\n",
      "epoch 6  | loss: 3.4203  | train_accuracy: 0.61    | train_auc: 0.61405 | test_accuracy: 0.62083 | test_auc: 0.62441 |  0:03:07s\n",
      "epoch 7  | loss: 0.79329 | train_accuracy: 0.60396 | train_auc: 0.59426 | test_accuracy: 0.60167 | test_auc: 0.59889 |  0:03:33s\n",
      "epoch 8  | loss: 0.72296 | train_accuracy: 0.59479 | train_auc: 0.6516  | test_accuracy: 0.61417 | test_auc: 0.6702  |  0:03:58s\n",
      "epoch 9  | loss: 0.62851 | train_accuracy: 0.63188 | train_auc: 0.60695 | test_accuracy: 0.63417 | test_auc: 0.60021 |  0:04:16s\n",
      "epoch 10 | loss: 0.53731 | train_accuracy: 0.69938 | train_auc: 0.73519 | test_accuracy: 0.71417 | test_auc: 0.7563  |  0:04:48s\n",
      "epoch 11 | loss: 0.55784 | train_accuracy: 0.58646 | train_auc: 0.75598 | test_accuracy: 0.5875  | test_auc: 0.76147 |  0:05:16s\n",
      "epoch 12 | loss: 0.55043 | train_accuracy: 0.60062 | train_auc: 0.80485 | test_accuracy: 0.60333 | test_auc: 0.79541 |  0:05:42s\n",
      "epoch 13 | loss: 0.5496  | train_accuracy: 0.71396 | train_auc: 0.82805 | test_accuracy: 0.73167 | test_auc: 0.84163 |  0:06:10s\n",
      "epoch 14 | loss: 0.49148 | train_accuracy: 0.73625 | train_auc: 0.83664 | test_accuracy: 0.73083 | test_auc: 0.83001 |  0:06:39s\n",
      "epoch 15 | loss: 0.5088  | train_accuracy: 0.73708 | train_auc: 0.83019 | test_accuracy: 0.7275  | test_auc: 0.83176 |  0:07:07s\n",
      "epoch 16 | loss: 0.51352 | train_accuracy: 0.76    | train_auc: 0.84491 | test_accuracy: 0.76167 | test_auc: 0.8421  |  0:07:34s\n",
      "epoch 17 | loss: 0.50854 | train_accuracy: 0.7675  | train_auc: 0.84509 | test_accuracy: 0.78083 | test_auc: 0.85398 |  0:08:07s\n",
      "epoch 18 | loss: 0.48603 | train_accuracy: 0.77146 | train_auc: 0.85207 | test_accuracy: 0.77333 | test_auc: 0.84181 |  0:08:34s\n",
      "epoch 19 | loss: 0.49848 | train_accuracy: 0.77604 | train_auc: 0.85108 | test_accuracy: 0.77583 | test_auc: 0.85261 |  0:09:02s\n",
      "Stop training because you reached max_epochs = 20 with best_epoch = 17 and best_test_auc = 0.85398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Desktop\\CISE - PR Acceptance Prediction\\venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7211    0.7247    0.7229      2009\n",
      "           1     0.8012    0.7983    0.7997      2791\n",
      "\n",
      "    accuracy                         0.7675      4800\n",
      "   macro avg     0.7611    0.7615    0.7613      4800\n",
      "weighted avg     0.7677    0.7675    0.7676      4800\n",
      "\n",
      "Validation Accuracy: 0.7808333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7414    0.7311    0.7362       502\n",
      "           1     0.8085    0.8166    0.8125       698\n",
      "\n",
      "    accuracy                         0.7808      1200\n",
      "   macro avg     0.7750    0.7738    0.7744      1200\n",
      "weighted avg     0.7804    0.7808    0.7806      1200\n",
      "\n",
      "Testing Accuracy: 0.768688901667625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8094    0.7698    0.7891      3910\n",
      "           1     0.7220    0.7672    0.7439      3046\n",
      "\n",
      "    accuracy                         0.7687      6956\n",
      "   macro avg     0.7657    0.7685    0.7665      6956\n",
      "weighted avg     0.7711    0.7687    0.7693      6956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(\n",
    "    n_d=128, n_a=128,\n",
    "    n_steps=20,\n",
    "    gamma=1.5,\n",
    "    lambda_sparse=1e-4,\n",
    "    mask_type=\"entmax\",\n",
    "\n",
    "    optimizer_fn=torch.optim.AdamW,\n",
    "    optimizer_params=dict(lr=0.009, weight_decay=1e-4),\n",
    "\n",
    "    scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "    scheduler_params={\"T_max\":50, \"eta_min\":1e-5}\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'test'],\n",
    "    eval_metric=['accuracy', 'auc'],\n",
    "    max_epochs=20,\n",
    "    batch_size=128,\n",
    "    virtual_batch_size=64,\n",
    "    patience=50,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "tab_pred_train = clf.predict(X_train)\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, tab_pred_train))\n",
    "print(classification_report(y_train, tab_pred_train, digits=4))\n",
    "\n",
    "tab_pred_val = clf.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, tab_pred_val))\n",
    "print(classification_report(y_val, tab_pred_val, digits=4))\n",
    "\n",
    "tab_pred_test = clf.predict(X_test)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, tab_pred_test))\n",
    "print(classification_report(y_test, tab_pred_test, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
